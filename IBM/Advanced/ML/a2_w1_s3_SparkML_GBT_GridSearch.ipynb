{"nbformat_minor": 1, "cells": [{"source": "import ibmos2spark\n\n# @hidden_cell\ncredentials = {\n    'endpoint': 'https://s3-api.us-geo.objectstorage.service.networklayer.com',\n    'api_key': 'iTfSE_YVE6zqnxjd1oK0E37R2aVYY4dFhXFFCljE1AcJ',\n    'service_id': 'iam-ServiceId-d4b06e46-293a-4417-b76c-2f16076a9353',\n    'iam_service_endpoint': 'https://iam.ng.bluemix.net/oidc/token'}\n\nconfiguration_name = 'os_b0f1407510994fd1b793b85137baafb8_configs'\ncos = ibmos2spark.CloudObjectStorage(sc, credentials, configuration_name, 'bluemix_cos')\n\nfrom pyspark.sql import SparkSession\nspark = SparkSession.builder.getOrCreate()\n# Since JSON data can be semi-structured and contain additional metadata, it is possible that you might face issues with the DataFrame layout.\n# Please read the documentation of 'SparkSession.read()' to learn more about the possibilities to adjust the data loading.\n# PySpark documentation: http://spark.apache.org/docs/2.0.2/api/python/pyspark.sql.html#pyspark.sql.DataFrameReader.json\n\n\ndf = spark.read.parquet(cos.url('hmp.parquet', 'courseraml-donotdelete-pr-qve0ttzezdeodc'))", "cell_type": "code", "metadata": {}, "outputs": [], "execution_count": 5}, {"source": "df.createOrReplaceTempView('df')\ndf_two_class = spark.sql(\"select * from df where class in ('Use_telephone','Standup_chair')\")", "cell_type": "code", "metadata": {}, "outputs": [], "execution_count": 6}, {"source": "splits = df_two_class.randomSplit([0.8, 0.2])\ndf_train = splits[0]\ndf_test = splits[1]", "cell_type": "code", "metadata": {}, "outputs": [], "execution_count": 7}, {"source": "from pyspark.ml.feature import StringIndexer, OneHotEncoder\nfrom pyspark.ml.linalg import Vectors\nfrom pyspark.ml.feature import VectorAssembler\nfrom pyspark.ml.feature import Normalizer\n\n\nindexer = StringIndexer(inputCol=\"class\", outputCol=\"label\")\n\nvectorAssembler = VectorAssembler(inputCols=[\"x\",\"y\",\"z\"],\n                                  outputCol=\"features\")\n\nnormalizer = Normalizer(inputCol=\"features\", outputCol=\"features_norm\", p=1.0)\n\n\n \n\n", "cell_type": "code", "metadata": {}, "outputs": [], "execution_count": 8}, {"source": "from pyspark.ml.classification import GBTClassifier\n\ngbt = GBTClassifier(labelCol=\"label\", featuresCol=\"features\", maxIter=10)", "cell_type": "code", "metadata": {}, "outputs": [], "execution_count": 9}, {"source": "\nfrom pyspark.ml import Pipeline\npipeline = Pipeline(stages=[indexer, vectorAssembler, normalizer,gbt])\n", "cell_type": "code", "metadata": {}, "outputs": [], "execution_count": 10}, {"source": "model = pipeline.fit(df_train)", "cell_type": "code", "metadata": {}, "outputs": [], "execution_count": 9}, {"source": "prediction = model.transform(df_train)", "cell_type": "code", "metadata": {}, "outputs": [], "execution_count": 10}, {"source": "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\nbinEval = MulticlassClassificationEvaluator().setMetricName(\"accuracy\") .setPredictionCol(\"prediction\").setLabelCol(\"label\")\n    \nbinEval.evaluate(prediction) ", "cell_type": "code", "metadata": {}, "outputs": [{"output_type": "error", "evalue": "name 'prediction' is not defined", "traceback": ["\u001b[0;31m\u001b[0m", "\u001b[0;31mNameError\u001b[0mTraceback (most recent call last)", "\u001b[0;32m<ipython-input-19-f114abce49f4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mbinEval\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mMulticlassClassificationEvaluator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msetMetricName\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"accuracy\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0msetPredictionCol\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"prediction\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msetLabelCol\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"label\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mbinEval\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprediction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m", "\u001b[0;31mNameError\u001b[0m: name 'prediction' is not defined"], "ename": "NameError"}], "execution_count": 19}, {"source": "prediction = model.transform(df_test)", "cell_type": "code", "metadata": {}, "outputs": [], "execution_count": 13}, {"source": "binEval.evaluate(prediction) ", "cell_type": "code", "metadata": {}, "outputs": [{"output_type": "execute_result", "data": {"text/plain": "0.9070227497527201"}, "execution_count": 14, "metadata": {}}], "execution_count": 14}, {"source": "from pyspark.ml.tuning import CrossValidator, ParamGridBuilder\n\nparamGrid = ParamGridBuilder() \\\n    .addGrid(normalizer.p, [1.0, 2.0, 10.0]) \\\n    .addGrid(gbt.maxBins, [2,4,8,16]) \\\n    .addGrid(gbt.maxDepth, [2,4,8,16]) \\\n    .build()\n", "cell_type": "code", "metadata": {}, "outputs": [], "execution_count": 13}, {"source": "\ncrossval = CrossValidator(estimator=pipeline,\n                          estimatorParamMaps=paramGrid,\n                          evaluator=MulticlassClassificationEvaluator(),\n                          numFolds=4)  \n", "cell_type": "code", "metadata": {}, "outputs": [], "execution_count": 24}, {"source": "cvModel = crossval.fit(df_train)", "cell_type": "code", "metadata": {}, "outputs": [], "execution_count": 25}, {"source": "prediction = cvModel.transform(df_test)", "cell_type": "code", "metadata": {}, "outputs": [], "execution_count": 22}, {"source": "binEval.evaluate(prediction) ", "cell_type": "code", "metadata": {}, "outputs": [{"output_type": "execute_result", "data": {"text/plain": "0.9111409068746953"}, "execution_count": 23, "metadata": {}}], "execution_count": 23}, {"source": "", "cell_type": "code", "metadata": {}, "outputs": [], "execution_count": null}], "metadata": {"kernelspec": {"display_name": "Python 2 with Spark 2.1", "name": "python2-spark21", "language": "python"}, "language_info": {"mimetype": "text/x-python", "nbconvert_exporter": "python", "version": "2.7.14", "name": "python", "pygments_lexer": "ipython2", "file_extension": ".py", "codemirror_mode": {"version": 2, "name": "ipython"}}}, "nbformat": 4}